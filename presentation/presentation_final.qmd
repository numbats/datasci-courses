---
title: "Defining Data Science"
subtitle: "A Case Study in Australia"
author: "Tina TSOU and Rachel WANG"
date: "17 October 2022"
format: 
  revealjs:
    logo: images/monash-one-line-black-rgb.png
    slide-number: true
    multiplex: true
    theme: assets/rladies.scss
    show-slide-number: all
    width: 1280
    height: 720
    controls: true
    css: assets/custom.css
    transition: convex
execute:
  echo: true
title-slide-attributes: 
  data-background-image: images/bgpic.jpg
  data-background-size: contain
  data-background-opacity: "0.6"

---
```{r setup, include = FALSE}
library(tidyverse)
library(tidytext)
library(SnowballC)
library(kableExtra)

knitr::opts_chunk$set(echo = FALSE,
                      warning = FALSE,
                      message= FALSE)
theme_set(theme_minimal())

```


## {#title-slide background-image="images/bg.jpg" background-opacity="0.5"}

![](images/datasci.jpg)

## Background Story & Motivations {background-image="images/bg.jpg" background-opacity="0.5"}

:::{.incremental}

- Data science has been a buzzword since it came out

- Is there a standard definition of data science in Australia?

- Does data science mean the same thing to universities and employers?

:::

## Agenda of the Day {background-image="images/bg.jpg" background-opacity="0.5"}


- Master of Data Science degree at Australian universities (Go8)

  - Data collection

  - Text analysis

- How employers define a 'data scientist'

- Key findings, limitations and future directions


## Master of Data Science at Go8 {background-image="images/bg.jpg" background-opacity="0.5"}

::: {.incremental}

- What are the main teaching contents? (e.g. statistics, maths, IT etc.)

- What could be the common skill sets of a data science graduate?

- Is there a 'standard structure' for data science degree across the Go8?

:::

# Data Collection {background-color="#006DAE"}

<!---
## Data Collection {.scrollable background-image="images/bg.jpg" background-opacity="0.5"}

:::{.incremental}

- Web scraping course information, list of subjects and unit outlines from universities' websites

- Performed using `RSelenium` and `rvest`

- Used robots.txt files as guidelines

:::

--->

<!---
## Web Scraping {.scrollable background-image="images/bg.jpg" background-opacity="0.5"}

Extract required information

<iframe src="https://handbook.monash.edu/2023/courses/C6009" width="100%" height="400px"></iframe>
--->

## Web Scraping ðŸ˜« {.scrollable background-image="images/bg.jpg" background-opacity="0.5"}

Initial settings and navigation to the course handbook

```{.r code-line-numbers="1-2|4-13|15|17-18|20-21"}
library(RSelenium)
library(rvest)

data <- tibble(Course = character(),
               Course_code = character(),
               Course_overview = character(),
               Unit = character(),
               Unit_code = character(),
               Overview = character(),
               Prerequisite = character(),
               Corequisite = character(),
               Prohibition = character(),
               Outcomes = character())
               
wait_time <- function() Sys.sleep(sample(3:5, 1))

rD <- rsDriver(browser="firefox", port=4778L, verbose=F)
remDr <- rD[["client"]]

remDr$navigate("https://handbook.unimelb.edu.au/2022/courses/mc-datasc")
course_html <- read_html(remDr$getPageSource()[[1]])
```


## Web Scraping Problems ðŸ†˜ {.scrollable background-image="images/bg.jpg" background-opacity="0.5"}

::: {.fragment}
::: {.incremental}
- Website elements not named
- Missing information
- Information not directly accessible
:::
::: 



::: {.fragment}
![](images/scrapuade.gif){fig-align="center"}

::: 


## Web Scraping Example: University of Adelaide {.scrollable background-image="images/bg.jpg" background-opacity="0.5"}

```{.r code-line-numbers="1-2|3-5|6-7|8-12|13"}
remDr$navigate(glue("https:{unit}"))
wait_time()
webElem <- remDr$findElement(
  using = "css",
  "html body div.keyline table tbody tr td div.content p table tbody tr td.odd a")
webElem$clickElement()
wait_time()
webElem2 <- remDr$findElement(
  using = "xpath",
  "/html/body/div[1]/table[4]/tbody/tr/td/div/a[2]")
webElem2$clickElement()
wait_time()
unit_html <- read_html(remDr$getPageSource()[[1]])
```


## Data We Collected {.smaller background-image="images/bg.jpg" background-opacity="0.5"}

```{r read-data, echo=FALSE, message=FALSE, warning=FALSE}
rmv_col <- function(x){
  read_csv(x) %>% 
  select(-`...1`)
}
unidata <- rmv_col("data/unidata.csv")
data_ssc <- rmv_col("data/ssc.csv") 
data_s <- rmv_col("data/stats.csv") 
data_cs <- rmv_col("data/cs.csv")
data_comp <- rmv_col("data/comp.csv") 
```

- The collected data contains **`r nrow(unidata)` units** from 8 universities

```{r}
unidata %>% 
  mutate(across(c(Outcomes, Overview, description), 
                ~ str_replace_all(.x, "\\\\", ""))) %>% 
  select(School, Course, Unit, Outcomes, Overview) %>% 
  kable() %>% 
  kable_styling(bootstrap_options = "condensed") %>% 
  scroll_box(height = "550px",
             width = "1250px")
```

# Text Analysis {background-color="#006DAE"}

## Unit Code Analysis  {.smaller background-image="images/bg.jpg" background-opacity="0.5"}

- **Faculty unit codes** e.g. FIT, ETC, MAT, tells us what type of faculty teaches the units for data science 

```{r}
unidata %>% 
  mutate(across(c(Outcomes, Overview, description), 
                ~ str_replace_all(.x, "\\\\", ""))) %>% 
  select(School, Course, Course_code, Unit, Unit_code) %>% 
  kable() %>% 
  kable_styling(bootstrap_options = "condensed") %>% 
  scroll_box(height = "350px",
             width = "1250px")
```

- Computational, statistical or mathematical? 

```{.r"}
math <- c("STAT", "MATH", "MATHS", "STATS", "MAT", "MAST", "ACTL", "QBUS")
it <- c("COMP", "FIT", "CITS", "INFS", "COSC", "CSSE", "CSYS", "EDPC", "INMT", "PHIL", "PHYS", "BUSN","DATA", "INFO", "INFS")
commerce <- c("ECON", "FINS", "MARK", "ACCT", "FINM", "MGMT", "MKTG")
spatial <- c("GEOM", "ITLS")
science <- c("EDUC", "SCIE", "SOCR")
health <- c("BINF", "BMS", "HTIN", "PUBH")
```


## Unit Code Analysis  {.smaller background-image="images/bg.jpg" background-opacity="0.5"}

::: {.panel-tabset}

### An Overview

```{r echo=FALSE}
math <- c("STAT", "MATH", "MATHS", "STATS", "MAT", "MAST", "ACTL", "QBUS")
it <- c("COMP", "FIT", "CITS", "INFS", "COSC", "CSSE", "CSYS", "EDPC", 
        "INMT", "PHIL", "PHYS", "BUSN","DATA", "INFO", "INFS")

commerce <- c("ECON", "FINS", "MARK", "ACCT", "FINM", "MGMT", "MKTG")
spatial <- c("GEOM", "ITLS")
science <- c("EDUC", "SCIE", "SOCR")
health <- c("BINF", "BMS", "HTIN", "PUBH")

comp <- unidata %>% 
  mutate(group = str_extract(Unit_code, "[A-Za-z]+")) %>% 
  group_by(School) %>% 
  count(group, sort = T) %>% 
  ungroup() %>% 
  mutate(category = case_when(group %in% it ~ "IT",
                              group %in% math ~ "Stat/Math",
                              group %in% commerce ~ "Commerce",
                              group %in% spatial ~ "Spatial",
                              group %in% science ~ "Science/Social Science",
                              group %in% health ~ "Health/Bioinfo/Biostat")) %>% 
  #Bioinformatics/Biostatistics
  mutate(category = if_else(is.na(category), "Other", category))

comp %>% 
  mutate(category = fct_reorder(category, n, sum)) %>% 
  ggplot(aes(x = n,
             y = category,
             fill = category)) +
  geom_col() +
  scale_fill_brewer(palette = "Dark2") +
  labs(x = "",
       y = "",
       title = "Teaching Content by Faculty") +
  theme(legend.position = "none") 
```

- **165 out of 298** units belongs to IT faculty, 79 units falls under math/stats

### University Breakdown

```{r echo=FALSE}
comp %>% 
  mutate(category = fct_reorder(category, n, sum)) %>% 
  group_by(School) %>% 
  mutate(prop = round(n/sum(n),4)) %>% 
  ungroup() %>% 
  ggplot(aes(x = prop,
             y = category,
             fill = category)) +
  geom_col() +
  scale_fill_brewer(palette = "Dark2") +
  labs(x = "",
       y = "",
       title = "Breakdown by Univeristy (Proportion)") +
  facet_wrap(~School, scales = "free_y") +
  theme(legend.position = "none")
```

- Overall computational and IT based, but proportion varies by university

:::

## Bigram of Outcomes and Overview {.scrollable .smaller background-image="images/bg.jpg" background-opacity="0.5"}

```{r echo=FALSE, warning=FALSE}
unidata_bigram <- unidata %>% 
  unnest_tokens(bigram, description, token = "ngrams", n = 2) %>% 
  separate(bigram,
           into = c("word1", "word2"),
           sep = " ") %>% 
  filter(!word1 %in% stop_words$word & !word2 %in% stop_words$word) %>%  
  filter(!word1 %in% c("content","topic", "unit", "subject", "final", "capstone", "involve", "project", "master", "practical", "programming") & 
         !word2 %in% c("student", "skill", "set", "piece", "concept", "capstone", "delivery", "domain", "manner", "due", "range", "unit", "master")) %>% 
  subset(!grepl("[0-9]", word1)) %>% 
  subset(!grepl("[0-9]", word2)) %>% 
  mutate(word = as_factor(paste(word1, word2, sep = " "))) %>%
  #filter(!word == "data science") %>% 
  distinct(School, Unit, word) %>% 
  group_by(School) %>% 
  count(word, sort = TRUE) %>% 
  ungroup() %>% 
  mutate(category = case_when(str_detect(word, "data") ~ "IT",
                              str_detect(word, "regression") ~ "Math",
                              str_detect(word, "software") ~ "IT",
                              str_detect(word, "information") ~"IT",
                              str_detect(word, "neural") ~ "IT",
                              str_detect(word, "artificial") ~ "AI",
                              str_detect(word, "machine") ~ "IT",
                              str_detect(word, "debugging") ~ "IT")) %>% 
  mutate(category = if_else(is.na(category), "Other", category))
```

```{r echo=FALSE}
unidata_bigram %>% 
  filter(n > 4) %>% 
  mutate(word = fct_reorder(word, n, sum))%>% 
  ggplot(aes(x=n,
             y = word))+
  geom_col(fill = "#006DAE")+
  #scale_fill_brewer(palette = "Dark2") +
  theme(legend.position = "bottom") +
  labs(y = "",
       fill = "Category",
       title = "Unit Bigram Overview (n > 4)") +
  scale_x_continuous(expand = c(0, 0.1))
```

::: {.incremental}
- count is too small to make meaningful interpretations

- similar words (e.g. research findings, designs etc.) are not grouped
::: 


## Further Analysis with the Concepts of Text Corpus {.smaller background-image="images/bg.jpg" background-opacity="0.5"}
::: {.incremental}

- Due to time limit we have only fitted a fairly basic Latent Dirichlet Allocation (LDA) model using `text2vec` package
  
  - Words are converted to *document-term matrix (DTM)*
  
  - A probabilistic model is fitted assumes a mixture of latent topics, each topic has a multinomial distribution for all words
  
- The model has to be trained by large amount of data pre-use

  - **4,448 Wikipedia articles** in *statistics (2,816), sociology (1,005) and computing (627)* are scraped as training data

  - Sociology data actually brings in noises to the model
  
  - The most informative result is provided by the model using only the **statistics** data
:::

## Text Analysis by Topics  {.scrollable .smaller background-image="images/bg.jpg" background-opacity="0.5"}

::: {.panel-tabset}

### Breakdown by University

:::: {.columns}

::: {.column width="80%"}
```{r echo=FALSE, fig.height=6}
# assign fixed colors to topics
colors <- RColorBrewer::brewer.pal(10, "Paired")
names(colors) <- levels(factor(1:10))
my_scale <- scale_fill_manual(name = "topic", values = colors)   

data_s %>% 
  mutate(topic = as_factor(topic)) %>% 
  #distinct(School, Unit, topic) %>% 
  group_by(School) %>% 
  count(topic, sort = TRUE) %>%
  mutate(prop = round(n/sum(n),4)) %>% 
  ungroup() %>% 
  mutate(topic = fct_reorder(topic, prop, sum))%>% 
  ggplot(aes(x = prop,
             y = topic,
             fill = topic))+
  geom_col() +
  my_scale +
  #scale_y_reordered() +
  facet_wrap(~School, scales = "free_y") +
  theme(legend.position = "none") +
  labs(x = "proportion",
       title = "Topics Proportion by University")

```
:::

::: {.column width="20%"}
```{r echo=FALSE}
rmv_col("data/term_s.csv") %>% 
  kable() %>% 
  column_spec(1, color = "white",
               background = "#A6CEE3") %>% 
  column_spec(2, color = "white",
               background = "#1F78B4") %>% 
  column_spec(3, color = "white",
               background = "#B2DF8A")%>% 
  column_spec(4, color = "white",
               background = "#33A02C")%>% 
  column_spec(5, color = "white",
               background = "#FB9A99")%>% 
  column_spec(6, color = "white",
               background = "#E31A1C") %>% 
  column_spec(7, color = "white",
               background = "#FDBF6F")%>% 
  column_spec(8, color = "white",
               background = "#FF7F00")%>% 
  column_spec(9, color = "white",
               background = "#CAB2D6") %>%
  column_spec(10, color = "white",
               background = "#6A3D9A") %>% 
  scroll_box(width = "200px")
```
:::

::::

- Words are stemmed using the `SnowballC` package 

- Topics 1 and 6 are the dominating topics across Go8, and both associated to computation, data, algorithm

- Topics 2, 5, 9, 10 contains more words like model, regression, sample, probability, Bayesian, hypothesis etc. indicating a more computational based statistical components

### Breakdown by Topic

:::: {.columns}

::: {.column width="80%"}
```{r echo=FALSE, fig.height=6}
data_s %>% 
  mutate(topic = as_factor(topic)) %>% 
  #distinct(School, Unit, topic) %>% 
  group_by(School) %>% 
  count(topic, sort = TRUE) %>%
  mutate(prop = round(n/sum(n),4)) %>% 
  ungroup() %>% 
  mutate(topic = fct_reorder(topic, prop, sum))%>% 
  ggplot(aes(x = prop,
             y = School,
             fill = School))+
  geom_col() +
  scale_fill_brewer(palette = "Paired") +
  #scale_y_reordered() +
  facet_wrap(~topic, scales = "free_y") +
  theme(legend.position = "none") +
  labs(x = "proportion",
       title = "Breakdown by Topic")

```
:::

::: {.column width="20%"}
```{r echo=FALSE}
rmv_col("data/term_s.csv") %>% 
  kable() %>% 
  scroll_box(width = "200px")
```
:::

::::

- Proportion occupied by Go8 for each topic is roughly even distributed

:::

<!---

## Still a Work in Progress... {background-image="images/bg.jpg" background-opacity="0.5"}

- It takes experienced linguists and huge efforts to build a text corpus

- The models are still relatively basic and requires more trimming and training

--->

# Employer's Perspective {background-color="#006DAE"}

## Data Science Jobs Data Overview{background-image="images/bg.jpg" background-opacity="0.5"}
```{r employer data, echo = FALSE}
jobs <- read_csv("../employer/listings2019_2021.csv")
emp_word_stat <- rmv_col("data/emp_stat.csv")
```
:::{.fragment}
::: {.incremental}
- 2,857 Data Science job postings on Seek.com from 2019-2021
- 535 Senior/ Managerial positions and 25 graduate program
:::
:::

:::{.fragment}
```{r employerdf}
jobs %>% 
  select(jobId, jobTitle, jobClassification, mobileAdTemplate, 25:49) %>% 
  head(.,10) %>% 
  kable() %>% 
  kable_styling(bootstrap_options = "condensed",
                font_size = 12) %>% 
  scroll_box(height = "550px",
             width = "1250px")
```
:::

## Job Analysis {.scrollable .smaller background-image="images/bg.jpg" background-opacity="0.5"}

::::: {.panel-tabset}

### Employer Bigram

```{r employer bigram, echo = FALSE}
emp_bigram <- jobs%>%
  select(c('jobId', 'jobTitle', 'jobClassification', 'advertiserName', 'workType', 'mobileAdTemplate')) %>% 
  unnest_tokens(bigram, mobileAdTemplate, token = "ngrams",n=2) %>% 
  separate(bigram, c("word1", "word2") , sep = " ") %>% 
  filter(!word1 %in% stop_words$word & !word2 %in% stop_words$word) %>% 
  subset(!grepl("[0-9]", word1)) %>% 
  subset(!grepl("[0-9]", word2)) %>%  
  mutate(stem1 = wordStem(word1, language = "english"),
         stem2 = wordStem(word2, language = "english"),
         bigram = paste(stem1, stem2)) %>% 
  group_by(jobId, jobTitle, jobClassification, advertiserName, workType) %>% 
  distinct(bigram) %>% 
  ungroup() 

emp_bigram %>%
  count(bigram, sort = TRUE) %>% 
  filter(n>300) %>% 
  ggplot(aes(x = n,y= fct_reorder(bigram, n), fill = n))+
  geom_col(fill = "#006DAE")+
  theme(legend.position = "none")+
  labs(title= "Jobs Bigram Overview (n > 300)", 
       y = "Bigrams")
```
:::{.incremental}
- Significantly more data than the previous data set
- Similar words not grouped
- Many terms related to data
:::

### Languages

```{r echo = FALSE}
jobs %>% select(c(25:49)) %>% 
  pivot_longer(everything(),
               names_to = "Program", 
               values_to = "sum") %>% 
  group_by(Program) %>% 
  summarise(sum = sum(sum)) %>%
  arrange(-sum) %>% 
  ggplot(aes(y = fct_reorder(Program, sum), 
             x= sum,
             fill = Program))+
  geom_col(fill = "#006DAE")+
  geom_text(aes(label = sum, hjust=0.1), color ="black")+
  theme(legend.position = "none")+
  labs(title = "Programming Languages Mentioned",
       y = "Language", x = "Count")
```

- Python is most popular followed by R and SQL
- Surprisingly not too much difference between Python and R

### Topic Breakdown
:::: {.columns}
::: {.column width="80%"}
```{r echo = FALSE}
emp_word_stat %>% 
  group_by(jobClassification) %>% 
  count(topic, sort = TRUE) %>% 
  mutate(prop = round(n/sum(n),4)) %>% 
  ungroup() %>% 
#  filter(n> 600) %>% 
  mutate(topic = fct_reorder(as.factor(topic), n, sum)) %>%
  ggplot(aes(x = prop,
             y = topic,
             fill = topic))+
  geom_col() +
  my_scale +
  facet_wrap(~jobClassification) +
  theme(legend.position = "none") +
  labs(title = "Topic Proportion by Job Classification")
```
:::

::: {.column width="20%"}
```{r echo = FALSE}
rmv_col("data/term_s.csv") %>% 
  kable() %>% 
  kable_styling(bootstrap_options = "condensed", font_size = 25) %>% 
  column_spec(1, color = "white",
               background = "#A6CEE3") %>% 
  column_spec(2, color = "white",
               background = "#1F78B4") %>% 
  column_spec(3, color = "white",
               background = "#B2DF8A")%>% 
  column_spec(4, color = "white",
               background = "#33A02C")%>% 
  column_spec(5, color = "white",
               background = "#FB9A99")%>% 
  column_spec(6, color = "white",
               background = "#E31A1C") %>% 
  column_spec(7, color = "white",
               background = "#FDBF6F")%>% 
  column_spec(8, color = "white",
               background = "#FF7F00")%>% 
  column_spec(9, color = "white",
               background = "#CAB2D6") %>%
  column_spec(10, color = "white",
               background = "#6A3D9A") %>%
  scroll_box(width = "200px") 
```
:::
:::: 

:::::

# Wrapping Up {background-color="#006DAE"}

## Limitations and Future Directions {background-image="images/bg.jpg" background-opacity="0.5"}
::: {.incremental}

- Data inconsistency

- No information on programming languages taught at universities

- Degrees offered at universities other than Go8 in Australia could be added

- The parameters of the LDA models could be tuned, and different models could be fitted

::: 

## To Sum Up! {.smaller background-image="images/bg.jpg" background-opacity="0.5"}

::: {.incremental}

- **What we have done**:

  1. Collected data for **298 units** across Go8 through web scraping

  2. Conducted exploratory analysis from various aspects on both university and employer data
  
  3. Built LDA models through web scraping **over 4000 Wikipedia articles** to establish our own 'text corpus'


- **Key findings from EDA**: 
  
  1. The Master of Data Science degrees offered at Go8 are mostly dominated by **computational component**, even the statistical aspects of it are more computational
  
  2. There is NO obvious 'standard structure or skill set' for data science degrees across Go8
  
  3. Most popular programming languages mentioned on job postings are Python, R and SQL
  
  4. Very subtle difference between the breakdown of topics for employer and university data
  
:::

# How will the definition evolve for the industry and academia? {background-image="images/bg.jpg" background-opacity="0.5"}
![](images/academiaindustry.jpeg){fig-align="center"}


## References and Resources {background-image="images/bg.jpg" background-opacity="0.5"}

- The slides are made using [Quarto](https://quarto.org/) with [Emi Tanaka's](https://github.com/emitanaka/talks) and [Danyang Dai's](https://github.com/DanyangDai) CSS design.

- Analysis on employer side are based on data set retrieved from [Exploring 2 years' of Data Scientist Job Listings](https://www.kaggle.com/code/nomilk/exploring-2-years-of-data-scientist-job-listings/data)

- The slides of this presentation, original source codes and data sets for this project are available at <https://github.com/numbats/datasci-courses>  


## {background-image="images/bg.jpg" background-opacity="0.5"}
![](images/qa.png){width="750" height="600" fig-align="center"}
