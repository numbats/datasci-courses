---
title: "Defining Data Science"
subtitle: "A Case Study in Australia"
author: "Tina and Rachel"
date: "17 October 2022"
format: 
  revealjs:
    logo: images/monash-one-line-black-rgb.png
    slide-number: true
    multiplex: true
    theme: assets/rladies.scss
    show-slide-number: all
    width: 1280
    height: 720
    controls: true
    css: assets/custom.css
    transition: convex
execute:
  echo: true
title-slide-attributes: 
  data-background-image: images/bgpic.jpg
  data-background-size: contain
  data-background-opacity: "0.6"

---

## {#title-slide background-image="images/bg.jpg" background-opacity="0.5"}

![](images/datasci.jpg)

## Background Story & Motivations {background-image="images/bg.jpg" background-opacity="0.5"}

- Data science has been a buzzword since it came out

- Is there a standard definition of data science in Australia?

- Does data science mean the same thing to universities and employers?

## Agenda of the Day {background-image="images/bg.jpg" background-opacity="0.5"}

:::{.incremental}

- Data science degree in Australian universities (Go8)

  - Data collection

  - Text analysis

- How employers define a 'data scientist'

- Key findings, limitations and future directions

:::

## Master of Data Science at Universities {background-image="images/bg.jpg" background-opacity="0.5"}


- What are the teaching contents? (e.g. statistics, maths, IT etc.)

- What could be the common skill sets of a data science graduate?

- Is there a 'standard structure' for data science degree across the Go8?

# Data Collection {background-color="#006DAE"}


## Data Collection {.scrollable background-image="images/bg.jpg" background-opacity="0.5"}
:::{.incremental}

- Web scrapping course information, list of subjects and unit outlines from universities' websites

- Performed using `RSelenium` and `rvest`

- Used robots.txt files as guidelines

:::

## Web Scraping {.scrollable background-image="images/bg.jpg" background-opacity="0.5"}

Extract required information

<iframe src="https://handbook.monash.edu/2023/courses/C6009" width="100%" height="400px"></iframe>


## Web Scraping {.scrollable background-image="images/bg.jpg" background-opacity="0.5"}

Initial settings and navigation to the course handbook

```{.r code-line-numbers="1-2|4-5|7-9|11-20|22-23"}
library(RSelenium)
library(rvest)

rD <- rsDriver(browser="firefox", port=4778L, verbose=F)
remDr <- rD[["client"]]

baseurl <- "https://handbook.unimelb.edu.au"
year <- 2022
wait_time <- function() Sys.sleep(sample(3:5, 1))

data <- tibble(Course = character(),
               Course_code = character(),
               Course_overview = character(),
               Unit = character(),
               Unit_code = character(),
               Overview = character(),
               Prerequisite = character(),
               Corequisite = character(),
               Prohibition = character(),
               Outcomes = character())

remDr$navigate("https://handbook.unimelb.edu.au/2022/courses/mc-datasc")
course_html <- read_html(remDr$getPageSource()[[1]])
```


## Web Scraping {.scrollable background-image="images/bg.jpg" background-opacity="0.5"}

Extract required information

<iframe src="https://handbook.monash.edu/2023/courses/C6009" width="100%" height="400px"></iframe>


## Data Collection - Web Scraping {.scrollable background-image="images/bg.jpg" background-opacity="0.5"}
:::: {.columns}

::: {.column width="50%"}
```{.r code-line-numbers="1-2|3-5|6-7|8-12|13"}
remDr$navigate(glue("https:{unit}"))
wait_time()
webElem <- remDr$findElement(
  using = "css",
  "html body div.keyline table tbody tr td div.content p table tbody tr td.odd a")
webElem$clickElement()
wait_time()
webElem2 <- remDr$findElement(
  using = "xpath",
  "/html/body/div[1]/table[4]/tbody/tr/td/div/a[2]")
webElem2$clickElement()
wait_time()
unit_html <- read_html(remDr$getPageSource()[[1]])
```
:::

::: {.column width="50%"}
::: {.incremental}
- 
- 
:::
:::
::::

## Be Mindful of Ethics Issues! {background-image="images/bg.jpg" background-opacity="0.5"}

- Getting blocked...

- Waiting time, pages that are prohibited for web scrapping

- robots.txt

## Data We Collected

```{r read-data, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(tidytext)
rmv_col <- function(x){
  read_csv(x) %>% 
  select(-`...1`)
}
unidata <- rmv_col("data/unidata.csv")
data_ssc <- rmv_col("data/ssc.csv") 
data_s <- rmv_col("data/stats.csv") 
data_cs <- rmv_col("data/cs.csv")
data_comp <- rmv_col("data/comp.csv") 

unidata %>% 
  mutate(across(c(Outcomes, Overview, description), 
                ~ str_replace_all(.x, "\\\\", ""))) %>% 
  select(School, Course, Unit, Outcomes, Overview) %>% 
  DT::datatable(height = "400px") %>%
  DT::formatStyle(columns = colnames(.), fontSize = '30%')
```

# Text Analysis {background-color="#006DAE"}

## Bigram of Outcomes and Overview {.scrollable .smaller background-image="images/bg.jpg" background-opacity="0.5"}

```{r echo=FALSE, warning=FALSE}
unidata_bigram <- unidata %>% 
  unnest_tokens(bigram, description, token = "ngrams", n = 2) %>% 
  separate(bigram,
           into = c("word1", "word2"),
           sep = " ") %>% 
  filter(!word1 %in% stop_words$word & !word2 %in% stop_words$word) %>%  
  filter(!word1 %in% c("content","topic", "unit", "subject", "final", "capstone", "involve", "project", "master", "practical", "programming") & 
         !word2 %in% c("student", "skill", "set", "piece", "concept", "capstone", "delivery", "domain", "manner", "due", "range", "unit", "master")) %>% 
  subset(!grepl("[0-9]", word1)) %>% 
  subset(!grepl("[0-9]", word2)) %>% 
  mutate(word = as_factor(paste(word1, word2, sep = " "))) %>%
  #filter(!word == "data science") %>% 
  distinct(School, Unit, word) %>% 
  group_by(School) %>% 
  count(word, sort = TRUE) %>% 
  ungroup() %>% 
  mutate(category = case_when(str_detect(word, "data") ~ "IT",
                              str_detect(word, "regression") ~ "Math",
                              str_detect(word, "software") ~ "IT",
                              str_detect(word, "information") ~"IT",
                              str_detect(word, "neural") ~ "IT",
                              str_detect(word, "artificial") ~ "AI",
                              str_detect(word, "machine") ~ "IT",
                              str_detect(word, "debugging") ~ "IT")) %>% 
  mutate(category = if_else(is.na(category), "Other", category))
```

```{r echo=FALSE}
unidata_bigram %>% 
  filter(n > 4) %>% 
  mutate(word = fct_reorder(word, n, sum))%>% 
  ggplot(aes(x=n,
             y = word))+
  geom_col(fill = "#006DAE")+
  #scale_fill_brewer(palette = "Dark2") +
  theme_minimal()+
  theme(legend.position = "bottom") +
  labs(y = "",
       fill = "Category",
       title = "An overview (n > 4)") +
  scale_x_continuous(expand = c(0, 0.1))
```

- count is too small to make meaningful interpretations

- similar words (e.g. research findings, designs etc.) are not grouped


## Unit Code Analysis  {.scrollable .smaller background-image="images/bg.jpg" background-opacity="0.5"}

* Faculty unit codes e.g. FIT, ETC, MAT, tells us what type of faculty teaches the units for data science 
* Computational, Statistical or Mathematical? 

```{r echo=FALSE}
math <- c("STAT", "MATH", "MATHS", "STATS", "MAT", "MAST", "ACTL", "QBUS")

it <- c("COMP", "FIT", "CITS", "INFS", "COSC", "CSSE", "CSYS", "EDPC", "INMT", "PHIL", "PHYS", #it
        "BUSN","DATA", #data
        "INFO", "INFS") #analytics

commerce <- c("ECON", "FINS", "MARK", "ACCT", "FINM", "MGMT", "MKTG")

spatial <- c("GEOM", "ITLS")

science <- c("EDUC", "SCIE", 
             "SOCR") #social science

health <- c("BINF", "BMS", "HTIN", "PUBH")

comp <- unidata %>% 
  mutate(group = str_extract(Unit_code, "[A-Za-z]+")) %>% 
  group_by(School) %>% 
  count(group, sort = T) %>% 
  ungroup() %>% 
  mutate(category = case_when(group %in% it ~ "IT",
                              group %in% math ~ "Stat/Math",
                              group %in% commerce ~ "Commerce",
                              group %in% spatial ~ "Spatial",
                              group %in% science ~ "Science/Social Science",
                              group %in% health ~ "Health/Bioinfo/Biostat")) %>% 
  #Bioinformatics/Biostatistics
  mutate(category = if_else(is.na(category), "Other", category))
```

```{r echo=FALSE}
comp %>% 
  mutate(category = fct_reorder(category, n, sum)) %>% 
  ggplot(aes(x = n,
             y = category,
             fill = category)) +
  geom_col() +
  scale_fill_brewer(palette = "Dark2") +
  labs(x = "",
       y = "",
       title = "Teaching content by faculty") +
  theme_minimal() +
  theme(legend.position = "none") 
```

- Conducted based on the first few characters from unit code

- Using only the unit code could be misleading

```{r echo=FALSE}
comp %>% 
  mutate(category = fct_reorder(category, n, sum)) %>% 
  group_by(School) %>% 
  mutate(prop = round(n/sum(n),4)) %>% 
  ungroup() %>% 
  ggplot(aes(x = prop,
             y = category,
             fill = category)) +
  geom_col() +
  scale_fill_brewer(palette = "Dark2") +
  labs(x = "",
       y = "",
       title = "Breakdown by univeristy - proportion") +
  facet_wrap(~School, scales = "free_y") +
  theme_minimal() +
  theme(legend.position = "none")
```

- Master of data science are dominated by IT at Monash, UADE, USYD and UWA

- More evenly distributed at ANU and UNSW

- UniMelb and UQ offers realtively higher proportion of stat/math contents

## Further Analysis with the Concepts of Text Corpus {.smaller background-image="images/bg.jpg" background-opacity="0.5"}

- Adapted the concepts of Word2Vec model, but due to time we have only fitted a fairly basic Latent Dirichlet Allocation (LDA) model

  - A three-level hierarchical Bayesian model
  
  - each word is modeled as a finite mixture over an underlying set of topics, texts are converted to numbers
  
  - words are 'close' to each other are then grouped together

- The model is trained by scrapping Wikipedia articles in **statistics, sociology and computing**

  - sociology data actually brings in noises to the model
  
  - the most informative results is provided by model using only the **statistics** or computing data
  
## Topics Breakdown by University {.scrollable .smaller background-image="images/bg.jpg" background-opacity="0.5"}

:::: {.columns}

::: {.column width="80%"}
```{r echo=FALSE, fig.height=6}
data_s %>% 
  mutate(topic = as_factor(topic)) %>% 
  #distinct(School, Unit, topic) %>% 
  group_by(School) %>% 
  count(topic, sort = TRUE) %>%
  mutate(prop = round(n/sum(n),4)) %>% 
  ungroup() %>% 
  mutate(topic = fct_reorder(topic, prop, sum))%>% 
  ggplot(aes(x = prop,
             y = topic,
             fill = topic))+
  geom_col() +
  scale_fill_brewer(palette = "Paired") +
  theme_minimal() +
  #scale_y_reordered() +
  facet_wrap(~School, scales = "free_y") +
  theme(legend.position = "none") +
  labs(x = "proportion",
       title = "Topic proportion - LDA_Stats")

```
:::

::: {.column width="20%"}
```{r echo=FALSE}
library(kableExtra)
rmv_col("data/term_s.csv") %>% 
  kable() %>% 
  scroll_box(width = "200px")
```
:::

::::

- Topics 1 and 6 are the dominating topics across Go8, and both associated to computation, data, algorithm

- Topics 2, 3, 5, 9, 10 contains more words like model, regression, sample, probability, Bayesian, hypothesis etc. indicating a more computational based statistical components

<!---

## Still a Work in Porgress... {background-image="images/bg.jpg" background-opacity="0.5"}

- It takes experienced linguists and huge efforts to build a text corpus

- The models are still relatively basic and requires more trimming and training

--->

# Employer Data {background-color="#006DAE"}
## Employer Perspectives {background-image="images/bg.jpg" background-opacity="0.5"}
```{r employer data, echo = FALSE}
jobs <- read_csv("../employer/listings2019_2021.csv")
emp_word_comp <- rmv_col("data/emp_comp.csv")
```
::: {.panel-tabset}
### Summary
- 2,857 Data Science job postings on Seek.com from 2019-2021
- 535 Senior/ Managerial positions and 25 graduate program

### Bigram

```{r employer bigram, echo = FALSE}
emp_bigram <- jobs%>%
  select(c('jobId', 'jobTitle', 'jobClassification', 'advertiserName', 'workType', 'mobileAdTemplate')) %>% 
  unnest_tokens(bigram, mobileAdTemplate, token = "ngrams",n=2) %>% 
  separate(bigram, c("word1", "word2") , sep = " ") %>% 
  filter(!word1 %in% stop_words$word & !word2 %in% stop_words$word ) %>% 
  mutate(bigram = paste(word1, word2)) %>% 
  group_by(jobId, jobTitle, jobClassification, advertiserName, workType) %>% 
  distinct(bigram) %>% 
  ungroup() 

emp_bigram %>%
  count(bigram, sort = TRUE) %>% 
  filter(n>300) %>% 
  ggplot(aes(x = n,y= fct_reorder(bigram, n), fill = n))+
  geom_col()+
  theme_minimal()+paletteer::scale_fill_paletteer_c("viridis::plasma")+
  theme(legend.position = "none")+
  labs(title= "Job Description Bigrams", 
       y = "Bigrams", 
       x= "Total Count")
```

### Languages

```{r echo = FALSE}
jobs %>% select(c(25:49)) %>% 
  pivot_longer(everything(),
               names_to = "Program", 
               values_to = "sum") %>% 
  group_by(Program) %>% 
  summarise(sum = sum(sum)) %>%
  arrange(-sum) %>% 
  ggplot(aes(y = fct_reorder(Program, sum), 
             x= sum,
             fill = Program))+
  geom_col()+
  geom_text(aes(label = sum, hjust=0.1), color ="black")+
  theme_minimal()+theme(legend.position = "none")+
  labs(title = "Programming languages mentioned in Job Ads",
       y = "Language", x = "Count")
```

### Topic Break Down
:::: {.columns}
::: {.column width="80%"}
```{r echo = FALSE}
emp_word_comp %>% 
#  distinct(jobTitle, jobClassification, topic) %>% 
  group_by(jobClassification) %>% 
  count(topic, sort = TRUE) %>% 
  ungroup() %>% 
  filter(n> 600) %>% 
  mutate(topic = fct_reorder(topic, n, sum))%>% #reorder_within(topic, n, School)
  ggplot(aes(x = n,
             y = topic,
             fill = topic))+
  geom_col() +
  scale_fill_brewer(palette = "Paired") +
  theme_minimal() +
  #scale_y_reordered() +
  facet_wrap(~jobClassification, scales = "free_y") +
  theme(legend.position = "none") +
  labs(title = "Job Classification Topic Count - LDA_COMP")
```
:::

::: {.column width="20%"}
```{r echo = FALSE}
rmv_col("data/emp_topics.csv") %>% 
  kable() %>% 
  scroll_box(width = "200px")
```
:::
:::: 

:::


## Limitations and Future Directions {background-image="images/bg.jpg" background-opacity="0.5"}

- Inconsistency of the data

- No information on programming languages taught at universities

- Not all universities have data science degree

- The LDA models fitted are not optimised

## To Sum Up! {.smaller background-image="images/bg.jpg" background-opacity="0.5"}

:::{incremental}

- What we have done:

  - Collected data across Go8 through web scrapping

  - Conducted exploratory analysis from various aspects on both university and employer data
  
  - Built LDA models through web scrapping Wikipedia articles to establish our own 'text corpus'


- Key findings: 

  - There is no obvious 'standard structure' for data science degree across Go8 (different unit codes etc.)
  
  - The degree is dominated by computational component, even the statistical aspects of it are more computational
  
  - employers want more python, how monash differs compare with other universities.

- post questions to the audience, how data science should evolve, where should it head

:::




## References and Resources {background-image="images/bg.jpg" background-opacity="0.5"}

-   The slides are made using [Quarto](https://quarto.org/) with [Emi Tanaka's](https://github.com/emitanaka/talks) and [Danyang Dai's](https://github.com/DanyangDai) CSS design.

- links for images used: 
<https://sundaskhalid.medium.com/data-science-the-what-where-and-why-fcf6fd86d76>

<https://www.google.com/url?sa=i&url=https%3A%2F%2Fkeepcalms.com%2Fp%2Fthanks-for-listening-it-s-time-for-questions%2F&psig=AOvVaw05JlCCDdUQAzj3LcIcBKLb&ust=1665630877564000&source=images&cd=vfe&ved=0CAwQjRxqFwoTCIiej9jc2foCFQAAAAAdAAAAABAJ>


## {background-image="images/bg.jpg" background-opacity="0.5"}

![](images/qa.png){width="750" height="600" fig-align="center"}