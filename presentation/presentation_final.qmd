---
title: "Defining Data Science"
subtitle: "A Case Study in Australia"
author: "Tina TSOU and Rachel WANG"
date: "17 October 2022"
format: 
  revealjs:
    logo: images/monash-one-line-black-rgb.png
    slide-number: true
    multiplex: true
    theme: assets/rladies.scss
    show-slide-number: all
    width: 1280
    height: 720
    controls: true
    css: assets/custom.css
    transition: convex
execute:
  echo: true
title-slide-attributes: 
  data-background-image: images/bgpic.jpg
  data-background-size: contain
  data-background-opacity: "0.6"

---
```{r setup, include = FALSE}
library(tidyverse)
library(tidytext)
library(kableExtra)

knitr::opts_chunk$set(echo = FALSE,
                      warning = FALSE,
                      message= FALSE)
theme_set(theme_minimal())

```


## {#title-slide background-image="images/bg.jpg" background-opacity="0.5"}

![](images/datasci.jpg)

## Background Story & Motivations {background-image="images/bg.jpg" background-opacity="0.5"}

:::{.incremental}

- Data science has been a buzzword since it came out

- Is there a standard definition of data science in Australia?

- Does data science mean the same thing to universities and employers?

:::

## Agenda of the Day {background-image="images/bg.jpg" background-opacity="0.5"}

:::{.incremental}

- Master of Data Science degree at Australian universities (Go8)

  - Data collection

  - Text analysis

- How employers define a 'data scientist'

- Key findings, limitations and future directions

:::

## Master of Data Science at Go8 {background-image="images/bg.jpg" background-opacity="0.5"}

::: {.incremental}

- What are the main teaching contents? (e.g. statistics, maths, IT etc.)

- What could be the common skill sets of a data science graduate?

- Is there a 'standard structure' for data science degree across the Go8?

:::

# Data Collection {background-color="#006DAE"}

<!---
## Data Collection {.scrollable background-image="images/bg.jpg" background-opacity="0.5"}

:::{.incremental}

- Web scrapping course information, list of subjects and unit outlines from universities' websites

- Performed using `RSelenium` and `rvest`

- Used robots.txt files as guidelines

:::

--->

<!---
## Web Scraping {.scrollable background-image="images/bg.jpg" background-opacity="0.5"}

Extract required information

<iframe src="https://handbook.monash.edu/2023/courses/C6009" width="100%" height="400px"></iframe>
--->

## Web Scraping ðŸ˜« {.scrollable background-image="images/bg.jpg" background-opacity="0.5"}

Initial settings and navigation to the course handbook

```{.r code-line-numbers="1-2|4-5|7-9|11-20|22-23"}
library(RSelenium)
library(rvest)

rD <- rsDriver(browser="firefox", port=4778L, verbose=F)
remDr <- rD[["client"]]

baseurl <- "https://handbook.unimelb.edu.au"
year <- 2022
wait_time <- function() Sys.sleep(sample(3:5, 1))

data <- tibble(Course = character(),
               Course_code = character(),
               Course_overview = character(),
               Unit = character(),
               Unit_code = character(),
               Overview = character(),
               Prerequisite = character(),
               Corequisite = character(),
               Prohibition = character(),
               Outcomes = character())

remDr$navigate("https://handbook.unimelb.edu.au/2022/courses/mc-datasc")
course_html <- read_html(remDr$getPageSource()[[1]])
```

<!---
## Web Scraping ðŸ˜« {.scrollable background-image="images/bg.jpg" background-opacity="0.5"}

Extract required information

<iframe src="https://handbook.monash.edu/2023/courses/C6009" width="100%" height="400px"></iframe>
--->

## Web Scraping ðŸ˜« {.scrollable background-image="images/bg.jpg" background-opacity="0.5"}
:::: {.columns}

::: {.column width="50%"}
```{.r code-line-numbers="1-2|3-5|6-7|8-12|13"}
remDr$navigate(glue("https:{unit}"))
wait_time()
webElem <- remDr$findElement(
  using = "css",
  "html body div.keyline table tbody tr td div.content p table tbody tr td.odd a")
webElem$clickElement()
wait_time()
webElem2 <- remDr$findElement(
  using = "xpath",
  "/html/body/div[1]/table[4]/tbody/tr/td/div/a[2]")
webElem2$clickElement()
wait_time()
unit_html <- read_html(remDr$getPageSource()[[1]])
```
:::

::: {.column width="50%"}
::: {.incremental}
- 
- 
:::
:::
::::

## Data We Collected {.smaller background-image="images/bg.jpg" background-opacity="0.5"}

```{r read-data, echo=FALSE, message=FALSE, warning=FALSE}
rmv_col <- function(x){
  read_csv(x) %>% 
  select(-`...1`)
}
unidata <- rmv_col("data/unidata.csv")
data_ssc <- rmv_col("data/ssc.csv") 
data_s <- rmv_col("data/stats.csv") 
data_cs <- rmv_col("data/cs.csv")
data_comp <- rmv_col("data/comp.csv") 
```

- The collected data contains **`r nrow(unidata)` units** from 8 universities

```{r}
unidata %>% 
  mutate(across(c(Outcomes, Overview, description), 
                ~ str_replace_all(.x, "\\\\", ""))) %>% 
  select(School, Course, Unit, Outcomes, Overview) %>% 
  kable() %>% 
  kable_styling(bootstrap_options = "condensed") %>% 
  scroll_box(height = "550px",
             width = "1250px")
```

# Text Analysis {background-color="#006DAE"}

## Unit Code Analysis  {.smaller background-image="images/bg.jpg" background-opacity="0.5"}

- **Faculty unit codes** e.g. FIT, ETC, MAT, tells us what type of faculty teaches the units for data science 

```{r}
unidata %>% 
  mutate(across(c(Outcomes, Overview, description), 
                ~ str_replace_all(.x, "\\\\", ""))) %>% 
  select(School, Course, Course_code, Unit, Unit_code) %>% 
  kable() %>% 
  kable_styling(bootstrap_options = "condensed") %>% 
  scroll_box(height = "350px",
             width = "1250px")
```

- Computational, Statistical or Mathematical? 

```{.r"}
math <- c("STAT", "MATH", "MATHS", "STATS", "MAT", "MAST", "ACTL", "QBUS")
it <- c("COMP", "FIT", "CITS", "INFS", "COSC", "CSSE", "CSYS", "EDPC", "INMT", "PHIL", "PHYS", "BUSN","DATA", "INFO", "INFS")
commerce <- c("ECON", "FINS", "MARK", "ACCT", "FINM", "MGMT", "MKTG")
spatial <- c("GEOM", "ITLS")
science <- c("EDUC", "SCIE", "SOCR")
health <- c("BINF", "BMS", "HTIN", "PUBH")
```


## Unit Code Analysis  {.smaller background-image="images/bg.jpg" background-opacity="0.5"}

::: {.panel-tabset}

### An Overview

```{r echo=FALSE}
math <- c("STAT", "MATH", "MATHS", "STATS", "MAT", "MAST", "ACTL", "QBUS")
it <- c("COMP", "FIT", "CITS", "INFS", "COSC", "CSSE", "CSYS", "EDPC", 
        "INMT", "PHIL", "PHYS", "BUSN","DATA", "INFO", "INFS")

commerce <- c("ECON", "FINS", "MARK", "ACCT", "FINM", "MGMT", "MKTG")
spatial <- c("GEOM", "ITLS")
science <- c("EDUC", "SCIE", "SOCR")
health <- c("BINF", "BMS", "HTIN", "PUBH")

comp <- unidata %>% 
  mutate(group = str_extract(Unit_code, "[A-Za-z]+")) %>% 
  group_by(School) %>% 
  count(group, sort = T) %>% 
  ungroup() %>% 
  mutate(category = case_when(group %in% it ~ "IT",
                              group %in% math ~ "Stat/Math",
                              group %in% commerce ~ "Commerce",
                              group %in% spatial ~ "Spatial",
                              group %in% science ~ "Science/Social Science",
                              group %in% health ~ "Health/Bioinfo/Biostat")) %>% 
  #Bioinformatics/Biostatistics
  mutate(category = if_else(is.na(category), "Other", category))

comp %>% 
  mutate(category = fct_reorder(category, n, sum)) %>% 
  ggplot(aes(x = n,
             y = category,
             fill = category)) +
  geom_col() +
  scale_fill_brewer(palette = "Dark2") +
  labs(x = "",
       y = "",
       title = "Teaching content by faculty") +
  theme(legend.position = "none") 
```
::: {.incremental}

- **165 out of 298** units belongs to IT faculty

- 79 units falls under math/stats

:::

### University Breakdown

```{r echo=FALSE}
comp %>% 
  mutate(category = fct_reorder(category, n, sum)) %>% 
  group_by(School) %>% 
  mutate(prop = round(n/sum(n),4)) %>% 
  ungroup() %>% 
  ggplot(aes(x = prop,
             y = category,
             fill = category)) +
  geom_col() +
  scale_fill_brewer(palette = "Dark2") +
  labs(x = "",
       y = "",
       title = "Breakdown by univeristy - proportion") +
  facet_wrap(~School, scales = "free_y") +
  theme(legend.position = "none")
```

::: {.incremental}

- Master of data science are dominated by IT at Monash, UADE, USYD and UWA

- More evenly distributed at ANU and UNSW

- UniMelb and UQ offers relatively higher proportion of stat/math contents

::: 

:::

## Bigram of Outcomes and Overview {.scrollable .smaller background-image="images/bg.jpg" background-opacity="0.5"}

```{r echo=FALSE, warning=FALSE}
unidata_bigram <- unidata %>% 
  unnest_tokens(bigram, description, token = "ngrams", n = 2) %>% 
  separate(bigram,
           into = c("word1", "word2"),
           sep = " ") %>% 
  filter(!word1 %in% stop_words$word & !word2 %in% stop_words$word) %>%  
  filter(!word1 %in% c("content","topic", "unit", "subject", "final", "capstone", "involve", "project", "master", "practical", "programming") & 
         !word2 %in% c("student", "skill", "set", "piece", "concept", "capstone", "delivery", "domain", "manner", "due", "range", "unit", "master")) %>% 
  subset(!grepl("[0-9]", word1)) %>% 
  subset(!grepl("[0-9]", word2)) %>% 
  mutate(word = as_factor(paste(word1, word2, sep = " "))) %>%
  #filter(!word == "data science") %>% 
  distinct(School, Unit, word) %>% 
  group_by(School) %>% 
  count(word, sort = TRUE) %>% 
  ungroup() %>% 
  mutate(category = case_when(str_detect(word, "data") ~ "IT",
                              str_detect(word, "regression") ~ "Math",
                              str_detect(word, "software") ~ "IT",
                              str_detect(word, "information") ~"IT",
                              str_detect(word, "neural") ~ "IT",
                              str_detect(word, "artificial") ~ "AI",
                              str_detect(word, "machine") ~ "IT",
                              str_detect(word, "debugging") ~ "IT")) %>% 
  mutate(category = if_else(is.na(category), "Other", category))
```

```{r echo=FALSE}
unidata_bigram %>% 
  filter(n > 4) %>% 
  mutate(word = fct_reorder(word, n, sum))%>% 
  ggplot(aes(x=n,
             y = word))+
  geom_col(fill = "#006DAE")+
  #scale_fill_brewer(palette = "Dark2") +
  theme(legend.position = "bottom") +
  labs(y = "",
       fill = "Category",
       title = "An overview (n > 4)") +
  scale_x_continuous(expand = c(0, 0.1))
```

::: {.incremental}
- count is too small to make meaningful interpretations

- similar words (e.g. research findings, designs etc.) are not grouped
::: 


## Further Analysis with the Concepts of Text Corpus {.smaller background-image="images/bg.jpg" background-opacity="0.5"}
::: {.incremental}

- Due to time limit we have only fitted a fairly basic Latent Dirichlet Allocation (LDA) model using `text2vec package`
  
  - words are converted to numerical vectors
  
  - distances between words are then computed, words are 'close' to each other are then grouped together

- The model has to be trained by large amount of data pre-use

  - **Over 4000 Wikipedia articles** in *statistics (2816), sociology (1005) and computing (627)* are scrapped as training data

  - sociology data actually brings in noises to the model
  
  - the most informative result is provided by model using only the **statistics** data
:::

## Text Analysis by Topics  {.scrollable .smaller background-image="images/bg.jpg" background-opacity="0.5"}

::: {.panel-tabset}

### Breakdown by University

:::: {.columns}

::: {.column width="80%"}
```{r echo=FALSE, fig.height=6}
data_s %>% 
  mutate(topic = as_factor(topic)) %>% 
  #distinct(School, Unit, topic) %>% 
  group_by(School) %>% 
  count(topic, sort = TRUE) %>%
  mutate(prop = round(n/sum(n),4)) %>% 
  ungroup() %>% 
  mutate(topic = fct_reorder(topic, prop, sum))%>% 
  ggplot(aes(x = prop,
             y = topic,
             fill = topic))+
  geom_col() +
  scale_fill_brewer(palette = "Paired") +
  #scale_y_reordered() +
  facet_wrap(~School, scales = "free_y") +
  theme(legend.position = "none") +
  labs(x = "proportion",
       title = "Topics proportion by university")

```
:::

::: {.column width="20%"}
```{r echo=FALSE}
rmv_col("data/term_s.csv") %>% 
  kable() %>% 
  scroll_box(width = "200px")
```
:::

::::

- Topics 1 and 6 are the dominating topics across Go8, and both associated to computation, data, algorithm

- Topics 2, 5, 9, 10 contains more words like model, regression, sample, probability, Bayesian, hypothesis etc. indicating a more computational based statistical components

### Breakdown by Topic

:::: {.columns}

::: {.column width="80%"}
```{r echo=FALSE, fig.height=6}
data_s %>% 
  mutate(topic = as_factor(topic)) %>% 
  #distinct(School, Unit, topic) %>% 
  group_by(School) %>% 
  count(topic, sort = TRUE) %>%
  mutate(prop = round(n/sum(n),4)) %>% 
  ungroup() %>% 
  mutate(topic = fct_reorder(topic, prop, sum))%>% 
  ggplot(aes(x = prop,
             y = School,
             fill = School))+
  geom_col() +
  scale_fill_brewer(palette = "Paired") +
  #scale_y_reordered() +
  facet_wrap(~topic, scales = "free_y") +
  theme(legend.position = "none") +
  labs(x = "proportion",
       title = "Breakdown by topic")

```
:::

::: {.column width="20%"}
```{r echo=FALSE}
rmv_col("data/term_s.csv") %>% 
  kable() %>% 
  scroll_box(width = "200px")
```
:::

::::

- Proportion occupied by Go8 for each topic is roughly even distributed

:::

<!---

## Still a Work in Progress... {background-image="images/bg.jpg" background-opacity="0.5"}

- It takes experienced linguists and huge efforts to build a text corpus

- The models are still relatively basic and requires more trimming and training

--->

# Employer Data {background-color="#006DAE"}
## Employer Perspectives {background-image="images/bg.jpg" background-opacity="0.5"}
```{r employer data, echo = FALSE}
jobs <- read_csv("../employer/listings2019_2021.csv")
emp_word_stat <- rmv_col("data/emp_stat.csv")
```
::: {.panel-tabset}
### Summary
::: {.incremental}
- 2,857 Data Science job postings on Seek.com from 2019-2021
- 535 Senior/ Managerial positions and 25 graduate program
:::
### Bigram

```{r employer bigram, echo = FALSE}
emp_bigram <- jobs%>%
  select(c('jobId', 'jobTitle', 'jobClassification', 'advertiserName', 'workType', 'mobileAdTemplate')) %>% 
  unnest_tokens(bigram, mobileAdTemplate, token = "ngrams",n=2) %>% 
  separate(bigram, c("word1", "word2") , sep = " ") %>% 
  filter(!word1 %in% stop_words$word & !word2 %in% stop_words$word ) %>% 
  mutate(bigram = paste(word1, word2)) %>% 
  group_by(jobId, jobTitle, jobClassification, advertiserName, workType) %>% 
  distinct(bigram) %>% 
  ungroup() 

emp_bigram %>%
  count(bigram, sort = TRUE) %>% 
  filter(n>300) %>% 
  ggplot(aes(x = n,y= fct_reorder(bigram, n), fill = n))+
  geom_col()+
  paletteer::scale_fill_paletteer_c("viridis::plasma")+
  theme(legend.position = "none")+
  labs(title= "Job Description Bigrams", 
       y = "Bigrams", 
       x= "Total Count")
```

### Languages

```{r echo = FALSE}
jobs %>% select(c(25:49)) %>% 
  pivot_longer(everything(),
               names_to = "Program", 
               values_to = "sum") %>% 
  group_by(Program) %>% 
  summarise(sum = sum(sum)) %>%
  arrange(-sum) %>% 
  ggplot(aes(y = fct_reorder(Program, sum), 
             x= sum,
             fill = Program))+
  geom_col()+
  geom_text(aes(label = sum, hjust=0.1), color ="black")+
  theme(legend.position = "none")+
  labs(title = "Programming languages mentioned in Job Ads",
       y = "Language", x = "Count")
```

### Topic Break Down
:::: {.columns}
::: {.column width="80%"}
```{r echo = FALSE}
emp_word_stat %>% 
#  distinct(jobTitle, jobClassification, topic) %>% 
  group_by(jobClassification) %>% 
  count(topic, sort = TRUE) %>% 
  ungroup() %>% 
#  filter(n> 600) %>% 
  mutate(topic = fct_reorder(as.factor(topic), n, sum)) %>%
  ggplot(aes(x = n,
             y = topic,
             fill = topic))+
  geom_col() +
  scale_fill_brewer(palette = "Paired") +
  #scale_y_reordered() +
  facet_wrap(~jobClassification) +
  theme(legend.position = "none") +
  labs(title = "Job Classification Topic Count - LDA_COMP")
```
:::

::: {.column width="20%"}
```{r echo = FALSE}
rmv_col("data/emp_topics.csv") %>% 
  kable() %>% 
  scroll_box(width = "200px")
```
:::
:::: 

:::


## Limitations and Future Directions {background-image="images/bg.jpg" background-opacity="0.5"}
::: {.incremental}

- Data inconsistency

- No information on programming languages taught at universities

- Degrees offered at universities other than Go8 in Australia could be added

- The parameters of the LDA models could be tuned, and different models could be fitted

::: 

## To Sum Up! {.smaller background-image="images/bg.jpg" background-opacity="0.5"}

::: {.incremental}

- **What we have done**:

  1. Collected data for **298 units** across Go8 through web scrapping

  2. Conducted exploratory analysis from various aspects on both university and employer data
  
  3. Built LDA models through web scrapping **over 4000 Wikipedia articles** to establish our own 'text corpus'


- **Key findings from EDA**: 
  
  1. The Master of Data Science degrees offered at Go8 are mostly dominated by **computational component**, even the statistical aspects of it are more computational
  
  2. There is NO obvious 'standard structure or skill set' for data science degrees across Go8
  
  3. Gaps between employer and uni???

- How data science would evolve, where should it head in Australia remains a question mark????

:::

## References and Resources {background-image="images/bg.jpg" background-opacity="0.5"}

- The slides are made using [Quarto](https://quarto.org/) with [Emi Tanaka's](https://github.com/emitanaka/talks) and [Danyang Dai's](https://github.com/DanyangDai) CSS design.

- Analysis on employer side are based on data set retrieved from [Exploring 2 years' of Data Scientist Job Listings](https://www.kaggle.com/code/nomilk/exploring-2-years-of-data-scientist-job-listings/data)

- The slides of this presentation, original source codes and data sets for this project are available at <https://github.com/numbats/datasci-courses>  


## {background-image="images/bg.jpg" background-opacity="0.5"}

![](images/qa.png){width="750" height="600" fig-align="center"}