---
title: "Defining Data Science"
subtitle: "A Case Study in Australia"
author: "Tina and Rachel"
date: "17 October 2022"
format: 
  revealjs:
    logo: images/monash-one-line-black-rgb.png
    slide-number: true
    multiplex: true
    theme: assets/rladies.scss
    show-slide-number: all
    width: 1280
    height: 720
    controls: true
    css: assets/custom.css
    transition: convex
execute:
  echo: true
title-slide-attributes: 
  data-background-image: images/bgpic.jpg
  data-background-size: contain
  data-background-opacity: "0.6"

---

## {#title-slide background-image="images/bg.jpg" background-opacity="0.5"}

![](images/datasci.jpg)

## Background Story & Motivations {background-image="images/bg.jpg" background-opacity="0.5"}

- Data science has been a buzzword since it came out

- Is there a standard definition of data science in Australia?

- Does data science mean the same thing to universities and employers?

## Agenda of the day {background-image="images/bg.jpg" background-opacity="0.5"}

:::{.incremental}

- Data science degree in Australian universities (Go8)

  - Data collection

  - Text analysis

- How employers define a 'data scientist'

- Key findings, limitations and future directions

:::

## Data Science Degrees at Universities {background-image="images/bg.jpg" background-opacity="0.5"}


- What are the teaching contents? (e.g. statistics, math, IT etc.)

- What could be the common skill sets of a data science graduate?

- Is there a 'standard structure' for data science degree across the Go8?


## Data Collection {.scrollable background-image="images/bg.jpg" background-opacity="0.5"}

- Web scrapping course information, list of subjects and unit outlines from universities' websites

- Performed using RSelenium and rvest

- Used robots.text files as guidelines


## Data Collection - Web Scraping {.scrollable background-image="images/bg.jpg" background-opacity="0.5"}

Initial settings and navigation to the course handbook

```{.r code-line-numbers="1-2|4-5|7-9|11-20|22-23"}
library(RSelenium)
library(rvest)

rD <- rsDriver(browser="firefox", port=4778L, verbose=F)
remDr <- rD[["client"]]

baseurl <- "https://handbook.unimelb.edu.au"
year <- 2022
wait_time <- function() Sys.sleep(sample(3:5, 1))

data <- tibble(Course = character(),
               Course_code = character(),
               Course_overview = character(),
               Unit = character(),
               Unit_code = character(),
               Overview = character(),
               Prerequisite = character(),
               Corequisite = character(),
               Prohibition = character(),
               Outcomes = character())

remDr$navigate("https://handbook.unimelb.edu.au/2022/courses/mc-datasc")
course_html <- read_html(remDr$getPageSource()[[1]])
```


## Data Collection - Web Scraping {.scrollable background-image="images/bg.jpg" background-opacity="0.5"}

Extract required information

<iframe src="https://handbook.monash.edu/2023/courses/C6009" width="100%" height="400px"></iframe>


```{.r code-inline-numbers=""}


```


## Be Mindful of Ethics Issues! {background-image="images/bg.jpg" background-opacity="0.5"}

- Getting blocked...

- Waiting time, pages that are prohibited for web scrapping

- Robots.text


## Text Analysis - Bigram {background-image="images/bg.jpg" background-opacity="0.5"}

```{r read-data, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(tidytext)

unidata <- read_csv("data/unidata.csv") %>% 
  select(-`...1`)

data_ssc <- read_csv("data/ssc.csv") %>% 
  select(-`...1`)

data_s <- read_csv("data/stats.csv") %>% 
  select(-`...1`)

data_cs <- read_csv("data/cs.csv") %>% 
  select(-`...1`)

data_comp <- read_csv("data/comp.csv") %>% 
  select(-`...1`)
```

:::: {.columns}

::: {.column width="40%"}

```{r echo=FALSE, warning=FALSE}
unidata_bigram <- unidata %>% 
  unnest_tokens(bigram, description, token = "ngrams", n = 2) %>% 
  separate(bigram,
           into = c("word1", "word2"),
           sep = " ") %>% 
  filter(!word1 %in% stop_words$word & !word2 %in% stop_words$word) %>%  
  filter(!word1 %in% c("content","topic", "unit", "subject", "final", "capstone", "involve", "project", "master", "practical", "programming") & 
         !word2 %in% c("student", "skill", "set", "piece", "concept", "capstone", "delivery", "domain", "manner", "due", "range", "unit", "master")) %>% 
  subset(!grepl("[0-9]", word1)) %>% 
  subset(!grepl("[0-9]", word2)) %>% 
  mutate(word = as_factor(paste(word1, word2, sep = " "))) %>%
  #filter(!word == "data science") %>% 
  distinct(School, Unit, word) %>% 
  group_by(School) %>% 
  count(word, sort = TRUE) %>% 
  ungroup() %>% 
  mutate(category = case_when(str_detect(word, "data") ~ "IT",
                              str_detect(word, "regression") ~ "Math",
                              str_detect(word, "software") ~ "IT",
                              str_detect(word, "information") ~"IT",
                              str_detect(word, "neural") ~ "IT",
                              str_detect(word, "artificial") ~ "AI",
                              str_detect(word, "machine") ~ "IT",
                              str_detect(word, "debugging") ~ "IT")) %>% 
  mutate(category = if_else(is.na(category), "Other", category))
```

```{r echo=FALSE}
unidata_bigram %>% 
  filter(n > 4) %>% 
  mutate(word = fct_reorder(word, n, sum))%>% 
  ggplot(aes(x=n,
             y = word,
             fill = category))+
  geom_col()+
  scale_fill_brewer(palette = "Dark2") +
  theme_minimal()+
  theme(legend.position = "bottom") +
  labs(y = "",
       fill = "Category",
       title = "An overview (n > 3)")
```

:::

::: {.column width="60%"}

```{r echo=FALSE}
unidata_bigram %>%
  group_by(School) %>% 
  mutate(prop = round(n/sum(n),4)) %>% 
  ungroup() %>% 
  filter(prop > 0.005) %>% 
  mutate(word = fct_reorder(word, prop, sum)) %>% 
  ggplot(aes(x = prop,
             y = word,
             fill = category))+
  geom_col()+
  scale_fill_brewer(palette = "Dark2") +
  theme_minimal()+
  facet_wrap(~School, scales = "free_y") +
  theme(legend.position = "bottom") +
  scale_x_continuous(breaks = c(0.005,0.01))+
  labs(y = "",
       x = "proportion",
       fill = "Category",
       title = "Bigram - break down by univeristy (prop > 0.005)")
```

:::

::::


- count is too small to make meaningful interpretations

## Break Down by Faculty {background-image="images/bg.jpg" background-opacity="0.5"}

Computational, Statistical or Mathematical? 

- Conducted based on the first few characters from unit code

- Using only the unit code could be misleading

## Further Analysis with the Concepts of Text Corpus {background-image="images/bg.jpg" background-opacity="0.5"}



- wordtovec, but due to time we'll only talk about lda

- word count after applying three models

- contructing tcm, document term matrix

- convering text data into something numerical

## Still a Work in Porgress... {background-image="images/bg.jpg" background-opacity="0.5"}

- It takes experienced linguists and huge efforts to build a text corpus

- The models are still relatively basic and requires more trimming and training


## Employer Perspectives {background-image="images/bg.jpg" background-opacity="0.5"}
```{r employer data, echo = FALSE}
jobs <- read_csv("../employer/listings2019_2021.csv")

```
::: {.panel-tabset}

### Job Description Bigram

```{r employer bigram, echo = FALSE}
emp_bigram <- jobs%>%
  select(c('jobId', 'jobTitle', 'jobClassification', 'advertiserName', 'workType', 'mobileAdTemplate')) %>% 
  unnest_tokens(bigram, mobileAdTemplate, token = "ngrams",n=2) %>% 
  separate(bigram, c("word1", "word2") , sep = " ") %>% 
  filter(!word1 %in% stop_words$word & !word2 %in% stop_words$word ) %>% 
  mutate(bigram = paste(word1, word2)) %>% 
  group_by(jobId, jobTitle, jobClassification, advertiserName, workType) %>% 
  distinct(bigram) %>% 
  ungroup() 

emp_bigram %>%
  count(bigram, sort = TRUE) %>% 
  filter(n>300) %>% 
  ggplot(aes(x = n,y= fct_reorder(bigram, n), fill = n))+
  geom_col()+
  theme_minimal()+paletteer::scale_fill_paletteer_c("viridis::plasma")+
  theme(legend.position = "none")+
  labs(title= "Job Description Bigrams", 
       y = "Bigrams", 
       x= "Total Count")
```

### Languages

```{r echo = FALSE}
jobs %>% select(c(25:49)) %>% 
  pivot_longer(everything(),
               names_to = "Program", 
               values_to = "sum") %>% 
  group_by(Program) %>% 
  summarise(sum = sum(sum)) %>%
  arrange(-sum) %>% 
  ggplot(aes(y = fct_reorder(Program, sum), 
             x= sum,
             fill = Program))+
  geom_col()+
  geom_text(aes(label = sum, hjust=0.1), color ="black")+
  theme_minimal()+theme(legend.position = "none")+
  labs(title = "Programming languages mentioned in Job Ads.",
       y = "Language", x = "Count")
```
### Salary
```{r job_salary, echo = FALSE}
library(priceR)

Salary <- jobs$salary_string %>% 
  extract_salary(
    include_periodicity = TRUE,
    working_weeks_per_year = 48 
    ) %>% 
  cbind(jobs, .)

Salary %>% 
  select(jobClassification, salary) %>% 
  filter(!is.na(salary) &salary < 1000000) %>%
  ggplot(aes(x = salary,
             y = jobClassification,
             color =..x..))+
  geom_point()+
 paletteer::scale_color_paletteer_c("viridis::plasma")+
  scale_x_continuous(labels = scales::dollar)+
  theme_minimal()+labs(title = "Salary distribution for Languages")+
  theme(legend.position = "none")
```




:::


## Limitations and Future Directions {background-image="images/bg.jpg" background-opacity="0.5"}

- Inconsistency of the data

- No information on programming languages taught at universities

- Not all universities have data science degree

- The LDA models fitted are not optimised

## To Sum Up! {.scrollable background-image="images/bg.jpg" background-opacity="0.5"}

:::{incremental}

- What we have done:

  - Collected data across Go8 through web scrapping

  - Conducted exploratory analysis from various aspects on both university and employer data
  
  - Built LDA models through web scrapping Wikipedia articles to establish our own 'text corpus'


- Key findings: 

  - There is no obvious 'standard structure' for data science degree across Go8 (different unit codes etc.)
  
  - The degree is dominated by computational component, even the statistical aspects of it are more computational
  
  - employers want more python, how monash differs compare with other universities.

- post questions to the audience, how data science should evolve, where should it head

:::




## References and Resources {background-image="images/bg.jpg" background-opacity="0.5"}

-   The slides are made using [Quarto](https://quarto.org/) with [Emi Tanaka's](https://github.com/emitanaka/talks) and [Danyang Dai's](https://github.com/DanyangDai) CSS design.

- links for images used: 
<https://sundaskhalid.medium.com/data-science-the-what-where-and-why-fcf6fd86d76>

<https://www.google.com/url?sa=i&url=https%3A%2F%2Fkeepcalms.com%2Fp%2Fthanks-for-listening-it-s-time-for-questions%2F&psig=AOvVaw05JlCCDdUQAzj3LcIcBKLb&ust=1665630877564000&source=images&cd=vfe&ved=0CAwQjRxqFwoTCIiej9jc2foCFQAAAAAdAAAAABAJ>


## {background-image="images/bg.jpg" background-opacity="0.5"}

![](images/qa.png){width="750" height="600" fig-align="center"}